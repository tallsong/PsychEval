from typing import Any, Dict
import re

from openai import OpenAI

from manager.base import EvaluationMethod
from utils import load_prompt
from jinja2 import Template
import json

from typing import List
from pydantic import BaseModel, ConfigDict # ðŸ‘ˆ ç¡®ä¿å¯¼å…¥ ConfigDict

class ItemScore(BaseModel):
    model_config = ConfigDict(extra='forbid')

    item: str
    score: float

class Items(BaseModel):                 # ç”¨å¯¹è±¡åŒ…ä¸€å±‚
    model_config = ConfigDict(extra='forbid')
    items: List[ItemScore]


class PANAS(EvaluationMethod):

    def _parse_panas_response(self, data: list) -> float:
        """è§£æžPANASé‡è¡¨çš„å“åº”"""
        # é¦–å…ˆï¼Œå°†åˆ—è¡¨è½¬æ¢ä¸ºä¸€ä¸ªæŸ¥æ‰¾å­—å…¸ï¼Œæ–¹ä¾¿å¿«é€ŸèŽ·å–åˆ†æ•°
        # keyæ˜¯ 'Interested', 'Excited' ç­‰, value æ˜¯ 2, 1 ç­‰
        data_lookup = {entry['item']: entry['score'] for entry in data}
        
        scores = {}
        
        # æ‚¨çš„åŽŸå§‹æƒ…æ„Ÿåˆ—è¡¨ï¼ˆä½œä¸ºå¤„ç†çš„åŸºå‡†ï¼‰
        emotions = ['Interested', 'Excited', 'Strong', 'Enthusiastic', 'Proud', 'Alert', 'Inspired', 'Determined', 'Attentive', 'Active','Distressed', 'Upset', 'Guilty', 'Scared', 'Hostile', 'Irritable', 'Ashamed', 'Nervous', 'Jittery', 'Afraid']

        for emotion in emotions:
            # ä»ŽæŸ¥æ‰¾å­—å…¸ä¸­èŽ·å–åŽŸå§‹åˆ†æ•°
            original_score = data_lookup.get(emotion)
            
            if original_score is not None:
                # å…³é”®ï¼šåº”ç”¨æ‚¨å®Œå…¨ç›¸åŒçš„åˆ†æ•°è®¡ç®—é€»è¾‘
                # (åŽŸå§‹åˆ†æ•°-1) * 2.5
                scores[f'panas_{emotion.lower()}'] = (original_score - 1) * 2.5


        # --- ä»Žè¿™é‡Œå¼€å§‹ï¼Œä¸‹é¢çš„æ‰€æœ‰é€»è¾‘éƒ½ä¸Žæ‚¨çš„åŽŸå§‹å‡½æ•°å®Œå…¨ç›¸åŒ ---
        
        # è®¡ç®—æ­£é¢æƒ…ç»ªå’Œè´Ÿé¢æƒ…ç»ªæ€»åˆ†
        # (åˆ—è¡¨å­—æ®µä¿æŒä¸å˜)
        
        
        positive_emotions = ['interested', 'excited', 'strong', 'enthusiastic', 'proud', 'alert', 'inspired', 'determined', 'attentive', 'active'] 
        negative_emotions = ['distressed', 'upset', 'guilty', 'scared', 'hostile', 'irritable', 'ashamed', 'nervous', 'jittery','afraid']
        
        positive_total = sum(scores.get(f'panas_{emotion}', 0) for emotion in positive_emotions)
        negative_total = sum(scores.get(f'panas_{emotion}', 0) for emotion in negative_emotions)
        
        final_scores = {}
        
        num_positive = len(positive_emotions)
        num_negative = len(negative_emotions)

        final_scores['positive'] = positive_total / num_positive if num_positive > 0 else 0
        final_scores['negative'] = negative_total / num_negative if num_negative > 0 else 0
        
        # (åˆ†æ•°è®¡ç®—æ–¹å¼ä¿æŒä¸å˜)
        final_score = (final_scores['positive'] - final_scores['negative'] + 10) / 2  # è½¬æ¢ä¸º0-10åˆ†åˆ¶
        
        return final_score

    async def evaluate(self, gpt_api, dialogue: Any, profile: dict = None) -> dict[str, float]:
        """è¯„ä¼°å¯¹è¯è´¨é‡"""
        scores = []
        
        schema = Items.model_json_schema()
        
        response_format = {
            "type": "json_schema",
            "json_schema": {
                "name": "Items",
                "strict": True,
                "schema": schema
            }
        }
        
        prompt = load_prompt("panas", "panas","cn")
        
        template = Template(prompt)
        prompt = template.render(intake_form=profile, diag=dialogue)

        # print(f"panas - panas prompt: {prompt}")

        messages=[{"role": "user", "content": prompt}]     
        criteria_output = await self.chat_api(gpt_api, messages=messages, response_format=response_format)
        score = json.loads(criteria_output)
        print(f"panas - panas raw output:", score)
        # scores.extend(score['items'])
            # è§£æž JSON

        # 3. å°†æ‚¨çš„æ•°æ®ï¼ˆåˆ—è¡¨ï¼‰è½¬æ¢ä¸ºå‡½æ•°æ‰€éœ€çš„å­—ç¬¦ä¸²æ ¼å¼
        # æž„å»ºä¸€ä¸ªåƒ "Interested: 2\nExcited: 1\n..." è¿™æ ·çš„å­—ç¬¦ä¸²
        # score = {'items': [
        #     {'item': 'Interested', 'score': 2}, {'item': 'Excited', 'score': 1}, {'item': 'Strong', 'score': 3}, {'item': 'Enthusiastic', 'score': 2}, {'item': 'Proud', 'score': 3}, {'item': 'Alert', 'score': 2}, {'item': 'Inspired', 'score': 2}, {'item': 'Determined', 'score': 3}, {'item': 'Attentive', 'score': 3}, {'item': 'Active', 'score': 2}, 
        # {'item': 'Distressed', 'score': 4}, 
        # {'item': 'Upset', 'score': 4}, 
        # {'item': 'Guilty', 'score': 4}, 
        # {'item': 'Scared', 'score': 3}, 
        # {'item': 'Hostile', 'score': 2}, 
        # {'item': 'Irritable', 'score': 3}, 
        # {'item': 'Ashamed', 'score': 4}, 
        # {'item': 'Nervous', 'score': 4}, 
        # {'item': 'Jittery', 'score': 3}, 
        # {'item': 'Afraid', 'score': 4}]}
        final_score = self._parse_panas_response(score['items'])
        return {"client": final_score}


    def get_name(self) -> str:
        return "PANAS"